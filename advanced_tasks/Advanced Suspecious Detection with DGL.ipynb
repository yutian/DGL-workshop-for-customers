{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "# 首先导入需要的包\n",
    "import os\n",
    "\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "from dgl.nn.pytorch.softmax import edge_softmax\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DGL反欺诈项目代码实践\n",
    "\n",
    "在这一任务里，我们会通过一个GNN模型的构建、探究和实验过程来学习如何使用DGL构建可被用于生产环境的代码。\n",
    "\n",
    "在本教程里，我们会完成如下的任务：\n",
    "\n",
    "1. 根据SOTA的算法论文，把计算公式转化成消息传递的模式；\n",
    "2. 根据消息传递的模式，实现单层GNN的模块；\n",
    "3. 叠加多层GNN模块，实现一个算法的模型；\n",
    "4. 使用一个小样例数据来探究模型的运行机制；\n",
    "5. 使用一个大图采样出的图数据，模拟模型的训练和推断。\n",
    "\n",
    "注：大图采样出的数据的内容不具有实际意义，所以训练和推断的结果没有参考，仅用于演示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法论文的思路转换\n",
    "\n",
    "阿里闲鱼团队在CIKM 2019上发了一篇进行[垃圾评论的检测算法](https://arxiv.org/abs/1908.10679)，被评为“最佳应用研究“论文。论文中利用了”用户“$\\to$“评论”$\\to$“商品”的二部图关系，通过含有Attention机制的特征传递方式，把“用户”和“商品”的特征加入“评论”的特征，帮助提升了对于“评论”的分类效果。\n",
    "<img src='./assets/XY-Test-Data.png' width=25%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 算法的原理\n",
    "\n",
    "- 通过Attention机制把“用户”+“评论”的特征发送给“商品”，并结合“商品”已有的特征，更新“商品”的特征；\n",
    "- 通过Attention机制把“商品”+“评论”的特征发送给“用户”，并结合“用户”已有的特征，更新“用户”的特征；\n",
    "- “用户”+“评论”+“商品”特征发给“评论”，并更新“评论”的特征；\n",
    "- 最后使用“用户”$||$“笔记”$||$“评论”作为特征进行“评论”的分类。其中，$||$是$concatenate$的意思。\n",
    "\n",
    "### 算法的核心公式\n",
    "可以看到，闲鱼的算法是针对一个二部图的双向重复计算。所以下面的公式介绍只解释一个方向的公式。\n",
    "\n",
    "- 对于一种点-“用户”的计算：\n",
    "\n",
    "    1. 首先把一个用户评论过的所有**商品**的特征和评论的特征concatenate起来。\n",
    "$$\\mathcal{H}_{IE}^{l-1} = \\{concat(h_i^{l-1}, h_e^{l-1}), \\forall e=(u, i)\\in E(u)\\}$$\n",
    "\n",
    "\n",
    "    2. 结合第1步里获取的合并特征，与“用户”的特征进行Attention的计算，获得“商品”+“评论”的带注意力组合的对“用户”的特征更新。\n",
    "$$\\mathcal{H}_{N(u)}^l = \\sigma(W_U^l * ATTN_U(W_{AU}^{l-1} * h_u^{l-1}, W_{AIE}^{l-1} * \\mathcal{H}_{IE}^{l-1}))$$\n",
    "其中，\n",
    "$$ATTN_U(W_{AU}^{l-1} * h_u^{l-1}, W_{AIE}^{l-1} * \\mathcal{H}_{IE}^{l-1}) \\implies \\mathcal{H}_{IE}^l$$\n",
    "\n",
    "\n",
    "    3. 使用“用户”自身的特征做非线性变换，然后与注意力更新后的特征进行组合，获得下一层的隐藏特征\n",
    "$$h_u^l = concat(V_U^l * h_u^{l-1}, \\mathcal{H}_{N(u)}^l)$$\n",
    "\n",
    "\n",
    "在这计算过程中，需要实现对于Attention的计算，原文中并没有给出。下面是按照[Attention is all you need](https://arxiv.org/abs/1706.03762)里面的原理给出计算公式。\n",
    "    \n",
    "    首先给出计算Attention前的符号定义：\n",
    "$$\\hat{h}_{u-1}^{l-1} = W_{AU}^{l-1} * h_u^{l-1},    \\hat{\\mathcal{H}}_{IE}^{l-1}=W_{AIE}^{l-1} * \\mathcal{H}_{IE}^{l-1}$$\n",
    "\n",
    "    a.1 通过点积计算出“商品”和“评价”对于“用户”的注意力原始值\n",
    "$$A_{attn\\_u} = \\hat{h}_{u-1}^{l-1} \\odot \\hat{\\mathcal{H}}_{IE}^{l-1}$$\n",
    "    \n",
    "    a.2 按照每个用户的“评论”边进行$softmax$计算。\n",
    "$$A_{attn\\_u} =softmax(A_{attn\\_u} )$$\n",
    "\n",
    "    a.3 把上一步softmax计算出的注意力系数和第1步合并的特征值广播相乘\n",
    "$$\\mathcal{\\hat{H}}_{IE}^l = \\mathcal{H}_{IE}^{l-1} * A_{attn\\_u}$$\n",
    "\n",
    "    a.4 最后一步把a.3的结果，按列求和，聚合成带注意力组合的对“用户”的特征更新\n",
    "$$\\mathcal{H}_{IE}^l = sum(\\mathcal{\\hat{H}}_{IE}^l,  dim=-1)$$\n",
    "    \n",
    "    \n",
    "    \n",
    "- 对边-“评论“的计算：\n",
    "$$h_e^l = \\sigma(W_E^l * concat(h_e^{l-1}, h_u^{l-1}, h_i^{l-1}))$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 按消息传递的模式构建模型\n",
    "\n",
    "\n",
    "\n",
    "下面首先构建GNN的一层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer(nn.Module):\n",
    "    \"\"\"\n",
    "    This layer is designed specifically for user Xianyu Graph algorithm.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_u_in, d_u_out, d_e_in, d_e_out, d_i_in, d_i_out):\n",
    "        super(layer, self).__init__()\n",
    "        self.act = F.relu\n",
    "\n",
    "        # 上面公式里对“评论”的三个权重，这里使用了先线性计算再concat的同质方式 \n",
    "        self.W_Ee = nn.Linear(d_e_in, d_e_out, bias=False)\n",
    "        self.W_Eu = nn.Linear(d_u_in, d_e_out, bias=False)\n",
    "        self.W_Ei = nn.Linear(d_i_in, d_e_out, bias=False)\n",
    "\n",
    "        # 上面公式里第2步的第二个和第三个权重，这里是双向的：u->i 和 i->u\n",
    "        # 1. i -> u 的权重\n",
    "        self.d_attn_ie_in = d_e_in + d_i_in\n",
    "        self.d_attn_u_out = self.d_attn_ie_in\n",
    "        self.W_ATTN_ie = nn.Linear(self.d_attn_ie_in, self.d_attn_u_out, bias=False)\n",
    "        self.W_ATTN_u = nn.Linear(d_u_in, self.d_attn_u_out, bias=False)\n",
    "\n",
    "        # 2. u -> i 的权重\n",
    "        self.d_attn_ue_in = d_e_in + d_u_in\n",
    "        self.d_attn_i_out = self.d_attn_u_out\n",
    "        self.W_ATTN_ue = nn.Linear(self.d_attn_ue_in, self.d_attn_i_out, bias=False)\n",
    "        self.W_ATTN_i = nn.Linear(d_i_in, self.d_attn_i_out, bias=False)\n",
    "\n",
    "        # 上面公式第2步里的第一权重，也是分u和i的\n",
    "        self.d_wu_in = self.d_attn_u_out\n",
    "        self.d_wu_out = int(d_u_out / 2)\n",
    "        self.W_nu = nn.Linear(self.d_wu_in, self.d_wu_out, bias=False)\n",
    "\n",
    "        self.d_wi_in = self.d_attn_i_out\n",
    "        self.d_wi_out = int(d_i_out / 2)\n",
    "        self.W_ni = nn.Linear(self.d_wi_in, self.d_wi_out, bias=False)\n",
    "\n",
    "        # 上面第3步里的权重\n",
    "        self.d_vu_out = d_u_out - self.d_wu_out\n",
    "        self.W_u = nn.Linear(d_u_in, self.d_vu_out, bias=False)\n",
    "\n",
    "        self.d_vi_out = d_i_out - self.d_wi_out\n",
    "        self.W_i = nn.Linear(d_i_in, self.d_vi_out, bias=False)\n",
    "        \n",
    "        \n",
    "    def forward(self, graph, u_feats, e_feats, i_feats):\n",
    "        \"\"\"\n",
    "        Specificlly For this algorithm, feat_dict has 3 types of features:\n",
    "        'User': l-1 layer's user features, in dict {'u': features}\n",
    "        'Edge': l-1 layer's edge features, in dict {'e': features}\n",
    "        'Item': l-1 layer's note features, in dict {'i': features}\n",
    "\n",
    "        This version, we have one edge but two types:\n",
    "            - 'comment_on'\n",
    "            - 'commented_by'\n",
    "\n",
    "        :param graph: bi-partitie\n",
    "        \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # L-1层的特征赋值\n",
    "        graph.nodes['user'].data['u'] = u_feats\n",
    "        graph.nodes['item'].data['i'] = i_feats\n",
    "        graph.edges['comment_on'].data['e'] = e_feats\n",
    "        graph.edges['commented_by'].data['e'] = e_feats\n",
    "\n",
    "        # 上面公式里的第1步concat计算\n",
    "        graph.apply_edges(lambda edges: {'h_ie': th.cat([edges.src['i'], edges.data['e']], dim=-1)}, etype='commented_by')\n",
    "        graph.apply_edges(lambda edges: {'h_ue': th.cat([edges.src['u'], edges.data['e']], dim=-1)}, etype='comment_on')\n",
    "\n",
    "        # 注意力的计算部分\n",
    "        graph.nodes['user'].data['h_attnu'] = self.W_ATTN_u(u_feats)\n",
    "        graph.nodes['item'].data['h_attni'] = self.W_ATTN_i(i_feats)\n",
    "        graph.edges['commented_by'].data['h_attne'] = self.W_ATTN_ie(graph.edges['commented_by'].data['h_ie'])\n",
    "        graph.edges['comment_on'].data['h_attne'] = self.W_ATTN_ue(graph.edges['comment_on'].data['h_ue'])\n",
    "\n",
    "        # a.1: 点积计算\n",
    "        graph.apply_edges(fn.e_dot_v('h_attne', 'h_attnu', 'edotv'), etype='commented_by')\n",
    "        graph.apply_edges(fn.e_dot_v('h_attne', 'h_attni', 'edotv'), etype='comment_on')\n",
    "\n",
    "        # a.2. 按边的softmax计算\n",
    "        graph.edges['commented_by'].data['sfm'] = edge_softmax(graph['commented_by'], graph.edges['commented_by'].data['edotv'])\n",
    "        graph.edges['comment_on'].data['sfm'] = edge_softmax(graph['comment_on'], graph.edges['comment_on'].data['edotv'])\n",
    "\n",
    "        # a.3. 广播softmax值到每条边\n",
    "        graph.apply_edges(lambda edges: {'attn': edges.data['h_attne'] * edges.data['sfm'].unsqueeze(dim=0).T},\n",
    "                          etype='commented_by')\n",
    "        graph.apply_edges(lambda edges: {'attn': edges.data['h_attne'] * edges.data['sfm'].unsqueeze(dim=0).T},\n",
    "                          etype='comment_on')\n",
    "\n",
    "        # a.4. 按列求和，聚合注意力加权后的值到端点\n",
    "        graph.update_all(fn.copy_e('attn', 'm'), fn.sum('m', 'agg_u'), etype='commented_by')\n",
    "        graph.update_all(fn.copy_e('attn', 'm'), fn.sum('m', 'agg_i'), etype='comment_on')\n",
    "\n",
    "        # 完成上面公式第2步\n",
    "        graph.nodes['user'].data['h_nu'] = self.act(self.W_nu(graph.nodes['user'].data['agg_u']))\n",
    "        graph.nodes['item'].data['h_ni'] = self.act(self.W_ni(graph.nodes['item'].data['agg_i']))\n",
    "\n",
    "        # 完成上面公式3的计算\n",
    "        graph.nodes['user'].data['u'] = th.cat([self.W_u(u_feats), graph.nodes['user'].data['h_nu']], dim=-1)\n",
    "        graph.nodes['item'].data['i'] = th.cat([self.W_i(i_feats), graph.nodes['item'].data['h_ni']], dim=-1)\n",
    "\n",
    "        # 上面公式里对“评论”的计算，这里是先矩阵相乘，再进行concat。\n",
    "        # 首先，完成矩阵相乘\n",
    "        graph.edges['comment_on'].data['h_e'] = self.W_Ee(e_feats)\n",
    "        graph.edges['commented_by'].data['h_e'] = self.W_Ee(e_feats)\n",
    "        graph.nodes['user'].data['h_u4e'] = self.W_Eu(u_feats)\n",
    "        graph.nodes['item'].data['h_i4e'] = self.W_Ei(i_feats)\n",
    "\n",
    "        # 然后，利用边的消息传递完成concat操作\n",
    "        graph.apply_edges(fn.u_add_e('h_u4e', 'h_e', 'h_ue'), etype='comment_on')\n",
    "        graph.apply_edges(fn.e_add_v('h_ue', 'h_i4e', 'e'), etype='comment_on')\n",
    "        graph.edges['comment_on'].data['e'] = self.act(graph.edges['comment_on'].data['e'])\n",
    "\n",
    "        graph.edges['commented_by'].data['e'] = graph.edges['comment_on'].data['e']\n",
    "\n",
    "        # 输出L层的特征\n",
    "        u_feats = graph.nodes['user'].data['u']\n",
    "        e_feats = graph.edges['comment_on'].data['e']\n",
    "        i_feats = graph.nodes['item'].data['i']\n",
    "\n",
    "        return u_feats, e_feats, i_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 堆叠多层形成一个GNN的模型\n",
    "\n",
    "这里我们按照通常GNN的设计，构建2层的算法模型。并再最后接一个全联接层，做一次2分类的logit输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Algorithm_Model(nn.Module):\n",
    "\n",
    "    def __init__(self, u_in_dim, e_in_dim, i_in_dim,\n",
    "                 hidden_dim, out_dim_ratio=2, num_class=2):\n",
    "\n",
    "        super(Algorithm_Model, self).__init__()\n",
    "        \n",
    "        # 定义模型内部使用的隐藏层维度，这里按照2倍来进行扩展隐藏层的维度\n",
    "        u_out_dim = u_in_dim * out_dim_ratio\n",
    "        e_out_dim = e_in_dim * out_dim_ratio\n",
    "        i_out_dim = i_in_dim * out_dim_ratio\n",
    "        g_out_dim = u_out_dim + e_out_dim + i_out_dim\n",
    "        \n",
    "        # 定义2层的GNN\n",
    "        self.layer_1 = layer(u_in_dim, hidden_dim, e_in_dim, hidden_dim, i_in_dim, hidden_dim)\n",
    "        self.layer_2 = layer(hidden_dim, u_out_dim, hidden_dim, e_out_dim, hidden_dim, i_out_dim)\n",
    "        # 定义最后的输出层\n",
    "        self.output = nn.Linear(g_out_dim, out_features=num_class)\n",
    "        \n",
    "    def forward(self, graph, u_features, e_features, i_features):\n",
    "        \n",
    "        h_u, h_e, h_i = self.layer_1(graph, u_features, e_features, i_features)\n",
    "        h_u = F.relu(h_u)\n",
    "        h_e = F.relu(h_e)\n",
    "        h_i = F.relu(h_i)\n",
    "        h_u, h_e, h_i = self.layer_2(graph, h_u, h_e, h_i)\n",
    "\n",
    "        # 使用DGL的消息传递机制来concat“用户”，“商品”和“评论”的特征\n",
    "        # 先赋值\n",
    "        graph.nodes['user'].data['u'] = h_u\n",
    "        graph.nodes['item'].data['i'] = h_i\n",
    "        graph.edges['comment_on'].data['e'] = h_e\n",
    "\n",
    "        # 按照边来concat两个端点的特征\n",
    "        graph.apply_edges(lambda edges:\n",
    "                          {'output': th.cat([edges.src['u'], edges.data['e'], edges.dst['i']], dim=-1)}, \n",
    "                          etype='comment_on')\n",
    "\n",
    "        # 最后的分类输出层计算\n",
    "        output = graph.edges['comment_on'].data['output']\n",
    "        logits = self.output(output)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用小样例数据来对模型的内部运作进行探究\n",
    "\n",
    "这里使用和原论文的例图结构一样一个极小数据，帮助了解模型的一层的内部运作机制，方便进一步理解算法和DGL的运作机制。\n",
    "<img src='./assets/XY-Test-Data.png' width=50%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_xy_graph(u, v):\n",
    "\n",
    "    graph = dgl.heterograph(\n",
    "        {('user', 'comment_on', 'item'): (u, v),\n",
    "         ('item', 'commented_by', 'user'): (v, u)}\n",
    "    )\n",
    "\n",
    "    return graph\n",
    "\n",
    "u = th.tensor([0,1,2,1,1,3,4,4])\n",
    "v = th.tensor([0,0,0,1,2,1,1,2])\n",
    "\n",
    "xy_graph = build_xy_graph(u, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 下面给这个图的节点和边赋一些随机的值\n",
    "\n",
    "- 用户节点: 6d，用户特征的值和用户自己对应的ID一致，例如，节点0是\\[0,0,0,0,0,0\\]，节点1是\\[1,1,1,1,1,1\\]，以此类推。\n",
    "- 商品节点: 3d, 商品特征的值和商品自己对应的ID一致，但是负数，例如，节点0是\\[0,0,0\\]，节点1是\\[-1,-1,-1\\]，以此类推。\n",
    "- 评论边:   7d, 对于“comment_on”和“commented_by”类型的边赋相同的值，特征的值和边对应的ID一致，但缩小1/10，例如，边0是\\[0,0,0,0,0,0,0\\]，边1是\\[0.1,0.1,0.1,0.1,0.1,0.1,0.1\\]，以此类推。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户输入特征：\n",
      " {'u': tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [2., 2., 2., 2., 2., 2.],\n",
      "        [3., 3., 3., 3., 3., 3.],\n",
      "        [4., 4., 4., 4., 4., 4.]])}\n",
      "商品输入特征：\n",
      " {'i': tensor([[-0., -0., -0.],\n",
      "        [-1., -1., -1.],\n",
      "        [-2., -2., -2.]])}\n",
      "评论的边的特征：\n",
      " {'e': tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
      "        [0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000],\n",
      "        [0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000],\n",
      "        [0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],\n",
      "        [0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000],\n",
      "        [0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000]])}\n"
     ]
    }
   ],
   "source": [
    "user_feats = th.from_numpy(np.ones([5,6]) * np.arange(5).reshape(5,1)).float()\n",
    "xy_graph.nodes['user'].data['u'] = user_feats\n",
    "print('用户输入特征：\\n', xy_graph.nodes['user'].data)\n",
    "\n",
    "item_feats = th.from_numpy(np.ones([3,3]) * np.arange(3).reshape(3,1) * -1).float()\n",
    "xy_graph.nodes['item'].data['i'] = item_feats\n",
    "print('商品输入特征：\\n', xy_graph.nodes['item'].data)\n",
    "\n",
    "edge_feats = th.from_numpy(np.ones([8,7]) * np.arange(8).reshape(8,1) * 0.1).float()\n",
    "xy_graph.edges['comment_on'].data['e'] = edge_feats\n",
    "xy_graph.edges['commented_by'].data['e'] = edge_feats\n",
    "print('评论的边的特征：\\n', xy_graph.edges['comment_on'].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初始化一层的实例\n",
    "\n",
    "这里会初始化我们定义一层layer，按照上面layer类init方法的定义，用户特征输入维度是5，商品特征输入维度是3，评论边特征输入维度是7。相应的隐藏维度定为20。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新一层用户的特征维度\n",
      " torch.Size([5, 20])\n",
      "新一层用户的特征\n",
      " tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.5511, -0.2027,  0.7250,  0.0562, -0.2796,  1.1621, -0.2732,  0.9873,\n",
      "          0.0972, -0.2080,  0.0805,  0.1811,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.1064,  0.0143,  0.0000,  0.0000],\n",
      "        [ 1.1021, -0.4055,  1.4499,  0.1125, -0.5593,  2.3241, -0.5464,  1.9746,\n",
      "          0.1944, -0.4159,  0.0000,  0.0000,  0.0000,  0.0000,  0.0381,  0.0000,\n",
      "          0.1561,  0.0621,  0.0000,  0.0632],\n",
      "        [ 1.6532, -0.6082,  2.1749,  0.1687, -0.8389,  3.4862, -0.8196,  2.9618,\n",
      "          0.2917, -0.6239,  0.0701,  0.2930,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.3022,  0.0729,  0.0000,  0.0000],\n",
      "        [ 2.2043, -0.8109,  2.8999,  0.2250, -1.1185,  4.6482, -1.0928,  3.9491,\n",
      "          0.3889, -0.8318,  0.0466,  0.3101,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.3795,  0.0999,  0.0000,  0.0000]], grad_fn=<CatBackward>)\n",
      "新一层评论边的特征维度\n",
      " torch.Size([8, 20])\n",
      "新一层评论边的特征\n",
      " tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [1.6313, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0570, 1.1901, 0.4526,\n",
      "         0.3525, 0.0388, 1.0317, 0.0000, 0.7902, 0.0000, 0.0000, 0.6216, 0.3089,\n",
      "         0.0000, 1.2052],\n",
      "        [3.2626, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1141, 2.3802, 0.9052,\n",
      "         0.7049, 0.0775, 2.0635, 0.0000, 1.5805, 0.0000, 0.0000, 1.2432, 0.6177,\n",
      "         0.0000, 2.4104],\n",
      "        [1.9068, 0.0000, 0.0000, 0.8343, 0.0000, 0.0000, 0.4829, 0.8870, 0.0000,\n",
      "         0.0520, 0.1768, 0.3901, 0.0000, 0.0181, 0.2646, 0.0000, 1.3125, 0.0000,\n",
      "         0.0000, 0.6831],\n",
      "        [2.0594, 0.0000, 0.0000, 1.7505, 0.0000, 0.0000, 0.9301, 0.6063, 0.0000,\n",
      "         0.0000, 0.3020, 0.0000, 0.0000, 0.0000, 0.5923, 0.0000, 2.0350, 0.0000,\n",
      "         0.0000, 0.1254],\n",
      "        [5.1695, 0.0000, 0.0000, 0.6249, 0.0000, 0.0000, 0.5970, 3.2672, 0.3891,\n",
      "         0.7569, 0.2543, 2.4536, 0.0000, 1.5986, 0.1364, 0.0000, 2.5557, 0.5207,\n",
      "         0.0000, 3.0935],\n",
      "        [6.8008, 0.0000, 0.0000, 0.5203, 0.0000, 0.0000, 0.6540, 4.4573, 0.8417,\n",
      "         1.1094, 0.2930, 3.4854, 0.0000, 2.3888, 0.0723, 0.0000, 3.1773, 0.8296,\n",
      "         0.0000, 4.2987],\n",
      "        [6.9533, 0.0000, 0.0000, 1.4365, 0.0000, 0.0000, 1.1013, 4.1766, 0.0000,\n",
      "         0.7458, 0.4183, 2.8502, 0.0000, 1.6284, 0.4001, 0.0000, 3.8998, 0.4725,\n",
      "         0.0000, 3.7410]], grad_fn=<ReluBackward0>)\n",
      "新一层商品的特征维度\n",
      " torch.Size([3, 20])\n",
      "新一层商品的特征\n",
      " tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.3117,  0.0296,  0.0443,  0.0000,  0.0000,  0.5025,\n",
      "          0.0000,  0.0000,  0.0000,  0.1945],\n",
      "        [ 0.0736, -0.3375, -1.1628, -0.4136,  0.0050, -0.6085,  0.0975,  0.3829,\n",
      "         -0.4897,  0.1529,  0.9586,  0.0290,  0.1361,  0.0038,  0.0000,  1.4896,\n",
      "          0.0000,  0.0000,  0.0000,  0.6648],\n",
      "        [ 0.1473, -0.6750, -2.3257, -0.8272,  0.0100, -1.2171,  0.1951,  0.7658,\n",
      "         -0.9795,  0.3057,  1.1040,  0.0117,  0.1568,  0.0170,  0.0000,  1.6961,\n",
      "          0.0000,  0.0000,  0.0000,  0.7888]], grad_fn=<CatBackward>)\n",
      "完成一层前向传播计算后的评论的边的特征：\n",
      " {'e': tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [1.6313, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0570, 1.1901, 0.4526,\n",
      "         0.3525, 0.0388, 1.0317, 0.0000, 0.7902, 0.0000, 0.0000, 0.6216, 0.3089,\n",
      "         0.0000, 1.2052],\n",
      "        [3.2626, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1141, 2.3802, 0.9052,\n",
      "         0.7049, 0.0775, 2.0635, 0.0000, 1.5805, 0.0000, 0.0000, 1.2432, 0.6177,\n",
      "         0.0000, 2.4104],\n",
      "        [1.9068, 0.0000, 0.0000, 0.8343, 0.0000, 0.0000, 0.4829, 0.8870, 0.0000,\n",
      "         0.0520, 0.1768, 0.3901, 0.0000, 0.0181, 0.2646, 0.0000, 1.3125, 0.0000,\n",
      "         0.0000, 0.6831],\n",
      "        [2.0594, 0.0000, 0.0000, 1.7505, 0.0000, 0.0000, 0.9301, 0.6063, 0.0000,\n",
      "         0.0000, 0.3020, 0.0000, 0.0000, 0.0000, 0.5923, 0.0000, 2.0350, 0.0000,\n",
      "         0.0000, 0.1254],\n",
      "        [5.1695, 0.0000, 0.0000, 0.6249, 0.0000, 0.0000, 0.5970, 3.2672, 0.3891,\n",
      "         0.7569, 0.2543, 2.4536, 0.0000, 1.5986, 0.1364, 0.0000, 2.5557, 0.5207,\n",
      "         0.0000, 3.0935],\n",
      "        [6.8008, 0.0000, 0.0000, 0.5203, 0.0000, 0.0000, 0.6540, 4.4573, 0.8417,\n",
      "         1.1094, 0.2930, 3.4854, 0.0000, 2.3888, 0.0723, 0.0000, 3.1773, 0.8296,\n",
      "         0.0000, 4.2987],\n",
      "        [6.9533, 0.0000, 0.0000, 1.4365, 0.0000, 0.0000, 1.1013, 4.1766, 0.0000,\n",
      "         0.7458, 0.4183, 2.8502, 0.0000, 1.6284, 0.4001, 0.0000, 3.8998, 0.4725,\n",
      "         0.0000, 3.7410]], grad_fn=<ReluBackward0>), 'h_ue': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.6313, -0.5638, -0.1003, -0.1047, -0.4982, -1.3496,  0.0570,  1.1901,\n",
      "          0.4526,  0.3525,  0.0388,  1.0317, -0.3182,  0.7902, -0.0641, -1.2597,\n",
      "          0.6216,  0.3089, -0.2151,  1.2052],\n",
      "        [ 3.2626, -1.1276, -0.2006, -0.2094, -0.9964, -2.6992,  0.1141,  2.3802,\n",
      "          0.9052,  0.7049,  0.0775,  2.0635, -0.6365,  1.5805, -0.1282, -2.5195,\n",
      "          1.2432,  0.6177, -0.4301,  2.4104],\n",
      "        [ 1.8773, -0.6214, -0.1822, -0.0591, -0.2590, -1.3048,  0.0142,  1.1452,\n",
      "          0.5867,  0.4787,  0.0643,  1.0188, -0.4024,  0.7668, -0.0622, -0.9616,\n",
      "          0.5585,  0.2111, -0.0256,  1.2763],\n",
      "        [ 2.0003, -0.6502, -0.2231, -0.0363, -0.1393, -1.2823, -0.0072,  1.1228,\n",
      "          0.6538,  0.5418,  0.0770,  1.0124, -0.4445,  0.7551, -0.0612, -0.8125,\n",
      "          0.5270,  0.1623,  0.0692,  1.3118],\n",
      "        [ 5.1399, -1.7490, -0.3828, -0.2685, -1.2553, -4.0040,  0.1283,  3.5254,\n",
      "          1.4919,  1.1836,  0.1418,  3.0823, -1.0389,  2.3473, -0.1904, -3.4811,\n",
      "          1.8017,  0.8289, -0.4557,  3.6867],\n",
      "        [ 6.7712, -2.3127, -0.4831, -0.3731, -1.7535, -5.3536,  0.1854,  4.7155,\n",
      "          1.9445,  1.5361,  0.1806,  4.1141, -1.3571,  3.1375, -0.2545, -4.7408,\n",
      "          2.4233,  1.1378, -0.6708,  4.8919],\n",
      "        [ 6.8942, -2.3415, -0.5240, -0.3503, -1.6339, -5.3312,  0.1640,  4.6931,\n",
      "          2.0115,  1.5992,  0.1933,  4.1076, -1.3992,  3.1258, -0.2535, -4.5917,\n",
      "          2.3918,  1.0889, -0.5760,  4.9274]], grad_fn=<BinaryReduceBackward>), 'h_attne': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.9315, -0.1586,  0.4770, -0.1752, -0.6405, -0.0140, -0.0832,  0.0379,\n",
      "          0.1870,  0.1165],\n",
      "        [ 1.8630, -0.3171,  0.9540, -0.3505, -1.2809, -0.0279, -0.1663,  0.0758,\n",
      "          0.3739,  0.2330],\n",
      "        [ 0.8190, -0.2258,  0.5010, -0.2747, -0.5736,  0.0091,  0.0767, -0.0081,\n",
      "          0.1964,  0.0925],\n",
      "        [ 0.7627, -0.2594,  0.5129, -0.3244, -0.5401,  0.0207,  0.1567, -0.0311,\n",
      "          0.2011,  0.0804],\n",
      "        [ 2.6820, -0.5429,  1.4549, -0.6252, -1.8545, -0.0188, -0.0896,  0.0677,\n",
      "          0.5703,  0.3255],\n",
      "        [ 3.6135, -0.7015,  1.9319, -0.8004, -2.4950, -0.0327, -0.1728,  0.1056,\n",
      "          0.7573,  0.4420],\n",
      "        [ 3.5572, -0.7351,  1.9439, -0.8502, -2.4615, -0.0212, -0.0928,  0.0826,\n",
      "          0.7620,  0.4299]], grad_fn=<MmBackward>), 'edotv': tensor([ 0.0000,  0.0000,  0.0000,  0.0355, -0.1622,  0.5730,  0.8417,  1.4502],\n",
      "       grad_fn=<BinaryReduceBackward>), 'sfm': tensor([0.3333, 0.3333, 0.3333, 0.2020, 0.1662, 0.3457, 0.4523, 0.8338],\n",
      "       grad_fn=<EdgeSoftmaxBackward>), 'attn': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.1050e-01, -5.2853e-02,  1.5900e-01, -5.8414e-02, -2.1349e-01,\n",
      "         -4.6514e-03, -2.7721e-02,  1.2638e-02,  6.2321e-02,  3.8836e-02],\n",
      "        [ 6.2100e-01, -1.0571e-01,  3.1799e-01, -1.1683e-01, -4.2698e-01,\n",
      "         -9.3027e-03, -5.5443e-02,  2.5276e-02,  1.2464e-01,  7.7671e-02],\n",
      "        [ 1.6541e-01, -4.5607e-02,  1.0118e-01, -5.5482e-02, -1.1585e-01,\n",
      "          1.8455e-03,  1.5496e-02, -1.6362e-03,  3.9661e-02,  1.8672e-02],\n",
      "        [ 1.2679e-01, -4.3130e-02,  8.5273e-02, -5.3935e-02, -8.9794e-02,\n",
      "          3.4385e-03,  2.6045e-02, -5.1717e-03,  3.3428e-02,  1.3370e-02],\n",
      "        [ 9.2720e-01, -1.8770e-01,  5.0300e-01, -2.1614e-01, -6.4114e-01,\n",
      "         -6.4894e-03, -3.0978e-02,  2.3415e-02,  1.9716e-01,  1.1252e-01],\n",
      "        [ 1.6344e+00, -3.1729e-01,  8.7383e-01, -3.6204e-01, -1.1285e+00,\n",
      "         -1.4802e-02, -7.8146e-02,  4.7783e-02,  3.4252e-01,  1.9991e-01],\n",
      "        [ 2.9658e+00, -6.1291e-01,  1.6207e+00, -7.0882e-01, -2.0523e+00,\n",
      "         -1.7658e-02, -7.7395e-02,  6.8897e-02,  6.3529e-01,  3.5847e-01]],\n",
      "       grad_fn=<MulBackward0>), 'h_e': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2298e-01, -2.8790e-02, -4.0945e-02,  2.2786e-02,  1.1961e-01,\n",
      "          2.2429e-02, -2.1410e-02, -2.2428e-02,  6.7077e-02,  6.3126e-02,\n",
      "          1.2757e-02, -6.4654e-03, -4.2101e-02, -1.1704e-02,  9.5007e-04,\n",
      "          1.4906e-01, -3.1539e-02, -4.8864e-02,  9.4750e-02,  3.5516e-02],\n",
      "        [ 2.4597e-01, -5.7580e-02, -8.1890e-02,  4.5572e-02,  2.3923e-01,\n",
      "          4.4858e-02, -4.2820e-02, -4.4856e-02,  1.3415e-01,  1.2625e-01,\n",
      "          2.5514e-02, -1.2931e-02, -8.4202e-02, -2.3408e-02,  1.9001e-03,\n",
      "          2.9813e-01, -6.3079e-02, -9.7727e-02,  1.8950e-01,  7.1033e-02],\n",
      "        [ 3.6895e-01, -8.6371e-02, -1.2284e-01,  6.8358e-02,  3.5884e-01,\n",
      "          6.7287e-02, -6.4230e-02, -6.7284e-02,  2.0123e-01,  1.8938e-01,\n",
      "          3.8272e-02, -1.9396e-02, -1.2630e-01, -3.5112e-02,  2.8502e-03,\n",
      "          4.4719e-01, -9.4618e-02, -1.4659e-01,  2.8425e-01,  1.0655e-01],\n",
      "        [ 4.9194e-01, -1.1516e-01, -1.6378e-01,  9.1144e-02,  4.7845e-01,\n",
      "          8.9716e-02, -8.5640e-02, -8.9712e-02,  2.6831e-01,  2.5250e-01,\n",
      "          5.1029e-02, -2.5862e-02, -1.6840e-01, -4.6815e-02,  3.8003e-03,\n",
      "          5.9625e-01, -1.2616e-01, -1.9545e-01,  3.7900e-01,  1.4207e-01],\n",
      "        [ 6.1492e-01, -1.4395e-01, -2.0473e-01,  1.1393e-01,  5.9807e-01,\n",
      "          1.1214e-01, -1.0705e-01, -1.1214e-01,  3.3538e-01,  3.1563e-01,\n",
      "          6.3786e-02, -3.2327e-02, -2.1051e-01, -5.8519e-02,  4.7503e-03,\n",
      "          7.4532e-01, -1.5770e-01, -2.4432e-01,  4.7375e-01,  1.7758e-01],\n",
      "        [ 7.3791e-01, -1.7274e-01, -2.4567e-01,  1.3672e-01,  7.1768e-01,\n",
      "          1.3457e-01, -1.2846e-01, -1.3457e-01,  4.0246e-01,  3.7876e-01,\n",
      "          7.6543e-02, -3.8793e-02, -2.5261e-01, -7.0223e-02,  5.7004e-03,\n",
      "          8.9438e-01, -1.8924e-01, -2.9318e-01,  5.6850e-01,  2.1310e-01],\n",
      "        [ 8.6089e-01, -2.0153e-01, -2.8662e-01,  1.5950e-01,  8.3729e-01,\n",
      "          1.5700e-01, -1.4987e-01, -1.5700e-01,  4.6954e-01,  4.4188e-01,\n",
      "          8.9301e-02, -4.5258e-02, -2.9471e-01, -8.1927e-02,  6.6504e-03,\n",
      "          1.0434e+00, -2.2078e-01, -3.4205e-01,  6.6325e-01,  2.4862e-01]],\n",
      "       grad_fn=<MmBackward>)}\n"
     ]
    }
   ],
   "source": [
    "test_layer = layer(d_u_in=6, d_u_out=20, d_e_in=7, d_e_out=20, d_i_in=3, d_i_out=20)\n",
    "\n",
    "# 前向传播\n",
    "user_out, edge_out, item_out = test_layer(xy_graph, user_feats, edge_feats, item_feats)\n",
    "\n",
    "print(\"新一层用户的特征维度\\n\", user_out.shape)\n",
    "print(\"新一层用户的特征\\n\", user_out)\n",
    "\n",
    "print(\"新一层评论边的特征维度\\n\", edge_out.shape)\n",
    "print(\"新一层评论边的特征\\n\", edge_out)\n",
    "\n",
    "print(\"新一层商品的特征维度\\n\", item_out.shape)\n",
    "print(\"新一层商品的特征\\n\", item_out)\n",
    "\n",
    "# 探究中间计算结果来进一步探究内部\n",
    "print('完成一层前向传播计算后的评论的边的特征：\\n', xy_graph.edges['comment_on'].data)\n",
    "\n",
    "# TODO: 您可以使用print方法来查看xy_graph的内部的数据信息来进一步了解每一步计算的内部机制。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验数据全图训练和推断\n",
    "\n",
    "为了展示如何完成对于这个模型的训练和推断，这里会使用从一个稍大的图数据。\n",
    "\n",
    "请注意：其中的标签是随机生成，仅用于演示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样例图有:15345条边\n",
      "用户特征维度:(11832, 6)\n",
      "商品特征维度:(3136, 3)\n",
      "评论特征维度:(15345, 7)\n"
     ]
    }
   ],
   "source": [
    "# 从本地文件读取实验用图数据文件\n",
    "data_path = \"./example_graph\"\n",
    "src = pd.read_csv(os.path.join(data_path, 'e_src.csv'))\n",
    "dst = pd.read_csv(os.path.join(data_path, 'e_dst.csv'))\n",
    "u_feats = pd.read_csv(os.path.join(data_path, 'user.csv'))\n",
    "e_feats = pd.read_csv(os.path.join(data_path, 'edge.csv'))\n",
    "i_feats = pd.read_csv(os.path.join(data_path, 'item.csv'))\n",
    "\n",
    "print(\"样例图有:{}条边\".format(e_feats.shape[0]))\n",
    "\n",
    "print(\"用户特征维度:{}\".format(u_feats.shape))\n",
    "print(\"商品特征维度:{}\".format(i_feats.shape))\n",
    "print(\"评论特征维度:{}\".format(e_feats.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用导入源和目标节点数据构建模型所需的DGL的图\n",
    "src_tensor = th.from_numpy(src.e_src.to_numpy())\n",
    "dst_tensor = th.from_numpy(dst.e_dst.to_numpy())\n",
    "graph = build_xy_graph(src_tensor, dst_tensor)\n",
    "\n",
    "# 生成可供模型使用的点和边的特征数据\n",
    "user_feats = th.from_numpy(u_feats.to_numpy()).float()\n",
    "edge_feats = th.from_numpy(e_feats.to_numpy()).float()\n",
    "item_feats = th.from_numpy(i_feats.to_numpy()).float()\n",
    "\n",
    "# 出于演示目的，这里随机选择1000条边，并给其中900条边赋0，表示为正常的（白）边；100条赋1，表示有疑问的（黑）边。\n",
    "num_of_edges = e_feats.shape[0]\n",
    "\n",
    "target_idx = np.random.choice(num_of_edges, 1000, replace=False)\n",
    "white_idx = target_idx[:900]\n",
    "black_idx = target_idx[900:]\n",
    "\n",
    "target_label = th.cat([th.zeros(900), th.ones(100)]).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练过程\n",
    "\n",
    "对于我们的实验数据，由于并不是很大，可以放进内存和显存，所以我们会采用全图训练。采样的方式可以参考大图采样的notebook。更多的DGL大图采样的例子可以在我们的[github](https://github.com/dmlc/dgl/tree/master/examples/pytorch/graphsage)里面找到。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 000 Epoch: train_loss: 0.7245 acc: 0.1750\n",
      "In 001 Epoch: train_loss: 0.7113 acc: 0.2500\n",
      "In 002 Epoch: train_loss: 0.6981 acc: 0.3750\n",
      "In 003 Epoch: train_loss: 0.6850 acc: 0.5760\n",
      "In 004 Epoch: train_loss: 0.6720 acc: 0.7930\n",
      "In 005 Epoch: train_loss: 0.6592 acc: 0.9000\n",
      "In 006 Epoch: train_loss: 0.6465 acc: 0.9000\n",
      "In 007 Epoch: train_loss: 0.6339 acc: 0.9000\n",
      "In 008 Epoch: train_loss: 0.6212 acc: 0.9000\n",
      "In 009 Epoch: train_loss: 0.6087 acc: 0.9000\n",
      "In 010 Epoch: train_loss: 0.5961 acc: 0.9000\n",
      "In 011 Epoch: train_loss: 0.5837 acc: 0.9000\n",
      "In 012 Epoch: train_loss: 0.5714 acc: 0.9000\n",
      "In 013 Epoch: train_loss: 0.5592 acc: 0.9000\n",
      "In 014 Epoch: train_loss: 0.5470 acc: 0.9000\n",
      "In 015 Epoch: train_loss: 0.5349 acc: 0.9000\n",
      "In 016 Epoch: train_loss: 0.5229 acc: 0.9000\n",
      "In 017 Epoch: train_loss: 0.5110 acc: 0.9000\n",
      "In 018 Epoch: train_loss: 0.4992 acc: 0.9000\n",
      "In 019 Epoch: train_loss: 0.4875 acc: 0.9000\n",
      "In 020 Epoch: train_loss: 0.4757 acc: 0.9000\n",
      "In 021 Epoch: train_loss: 0.4639 acc: 0.9000\n",
      "In 022 Epoch: train_loss: 0.4522 acc: 0.9000\n",
      "In 023 Epoch: train_loss: 0.4405 acc: 0.9000\n",
      "In 024 Epoch: train_loss: 0.4291 acc: 0.9000\n",
      "In 025 Epoch: train_loss: 0.4180 acc: 0.9000\n",
      "In 026 Epoch: train_loss: 0.4073 acc: 0.9000\n",
      "In 027 Epoch: train_loss: 0.3970 acc: 0.9000\n",
      "In 028 Epoch: train_loss: 0.3872 acc: 0.9000\n",
      "In 029 Epoch: train_loss: 0.3780 acc: 0.9000\n",
      "\n",
      "Model parameters are saved to ./model.pth\n"
     ]
    }
   ],
   "source": [
    "# --------------- 1. 构建GNN模型 ------------------ #\n",
    "# 根据我们的数据的维度构建模型\n",
    "model = Algorithm_Model(u_in_dim=6, e_in_dim=7, i_in_dim=3, hidden_dim=20)\n",
    "\n",
    "# --------------- 2. 构建损失函数和优化器 ----------- #\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam([{'params': model.parameters(), 'lr':0.001, 'weight_decay':5e-4}])\n",
    "\n",
    "# --------------- 3. 进行模型训练 ------------------ #\n",
    "MAX_EPOCH = 30\n",
    "for epoch in range(MAX_EPOCH):\n",
    "    # 设置成训练模式\n",
    "    model.train()\n",
    "    \n",
    "    # 前向传播\n",
    "    logits = model(graph, user_feats, edge_feats, item_feats)\n",
    "    \n",
    "    # 提取标签的边\n",
    "    train_logits = logits[target_idx]\n",
    "    \n",
    "    # 计算loss\n",
    "    train_loss = loss_fn(train_logits, target_label)\n",
    "\n",
    "    # 计算指标\n",
    "    train_pred = train_logits.argmax(1)\n",
    "    train_acc = (train_pred == target_label).float().mean()\n",
    "\n",
    "    # 反向传播\n",
    "    opt.zero_grad()\n",
    "    train_loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    model.eval()\n",
    "    # 这里省略了validation的代码，用户应该能简单的加入相应的代码\n",
    "\n",
    "    print('In {:03d} Epoch: train_loss: {:.4f} acc: {:.4f}'.\n",
    "        format(epoch, train_loss, train_acc))\n",
    "\n",
    "# --------------- 4. 保存模型 ------------------ #\n",
    "model_para_dict = model.state_dict()\n",
    "model_path = os.path.join('./', 'model' + '.pth')\n",
    "th.save(model_para_dict, model_path)\n",
    "print(\"\\nModel parameters are saved to {}\".format(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推断过程\n",
    "\n",
    "由于我们的模型是一个inductive的模型，即不依赖于原图的结构，所以可以对新加入的边进行预测推断，包括原图已经发生改变的情况。\n",
    "\n",
    "出于演示目的，我们人为地在原图里增加1条新的边和新边的特征。为简单起见，这里是对已经存在的2个点增加新边，而不再创建新的点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15346, 7])\n"
     ]
    }
   ],
   "source": [
    "# 在源和目标点列表的最后加入新的边\n",
    "new_src_tensor = th.cat([src_tensor, th.tensor([11509])])\n",
    "new_dst_tensor = th.cat([dst_tensor, th.tensor([142])])\n",
    "\n",
    "# 在边特征的最后加入新的边的特性\n",
    "new_edge_feats = th.cat([edge_feats, th.tensor([[0.257663393,1,0,0,1,0,0]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11832\n",
      "3136\n",
      "15346\n"
     ]
    }
   ],
   "source": [
    "# 重构我们的图\n",
    "new_graph = build_xy_graph(new_src_tensor, new_dst_tensor)\n",
    "print(new_graph.number_of_nodes('user'))\n",
    "print(new_graph.number_of_nodes('item'))\n",
    "print(new_graph.number_of_edges('comment_on'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我们新边的预测logits是: tensor([[ 0.3467, -0.9935]])\n",
      "我们新边的预测标签是: tensor([0])\n"
     ]
    }
   ],
   "source": [
    "# 导入保存的模型\n",
    "stat_dict = th.load(model_path, map_location=th.device('cpu'))\n",
    "\n",
    "xy_model = Algorithm_Model(u_in_dim=6, e_in_dim=7, i_in_dim=3, hidden_dim=20)\n",
    "xy_model.load_state_dict(stat_dict)\n",
    "\n",
    "# 进行预测推断\n",
    "logits = xy_model(new_graph, user_feats, new_edge_feats, item_feats)\n",
    "target_logits = logits[-1:]\n",
    "\n",
    "pred = logits.argmax(1)\n",
    "target_pred = pred[-1:]\n",
    "print(\"我们新边的预测logits是: {}\".format(target_logits.detach()))\n",
    "print(\"我们新边的预测标签是: {}\".format(target_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
